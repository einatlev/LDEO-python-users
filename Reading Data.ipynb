{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) mat files (scipy.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat as loadmat #this is the scipy module that loads .mat files\n",
    "from scipy.io import savemat as savemat #this is the scipy module that saves .mat files\n",
    "\n",
    "matfile = loadmat('python_test.mat')  # load .mat file\n",
    "\n",
    "array1 = matfile['array1']\n",
    "array2 = matfile['array2']\n",
    "\n",
    "array1.shape\n",
    "\n",
    "type(array1)\n",
    "\n",
    "savemat('python_test_save.mat',{'array1':array1}) #save numpy array to .mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) csv, txt, xls with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>net</th>\n",
       "      <th>id</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-31 23:53:37.000</th>\n",
       "      <td>60.252000</td>\n",
       "      <td>-152.7081</td>\n",
       "      <td>90.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11155107</td>\n",
       "      <td>2014-02-05T19:34:41.515Z</td>\n",
       "      <td>26km S of Redoubt Volcano, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31 23:48:35.452</th>\n",
       "      <td>37.070300</td>\n",
       "      <td>-115.1309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ml</td>\n",
       "      <td>4</td>\n",
       "      <td>171.43</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn00436847</td>\n",
       "      <td>2014-02-01T01:35:09.000Z</td>\n",
       "      <td>32km S of Alamo, Nevada</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31 23:47:24.000</th>\n",
       "      <td>64.671700</td>\n",
       "      <td>-149.2528</td>\n",
       "      <td>7.10</td>\n",
       "      <td>1.30</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11151142</td>\n",
       "      <td>2014-02-01T00:03:53.010Z</td>\n",
       "      <td>12km NNW of North Nenana, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31 23:30:54.000</th>\n",
       "      <td>63.188700</td>\n",
       "      <td>-148.9575</td>\n",
       "      <td>96.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak11151135</td>\n",
       "      <td>2014-01-31T23:41:25.007Z</td>\n",
       "      <td>22km S of Cantwell, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31 23:30:52.210</th>\n",
       "      <td>32.616833</td>\n",
       "      <td>-115.6925</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.34</td>\n",
       "      <td>ml</td>\n",
       "      <td>6</td>\n",
       "      <td>285.00</td>\n",
       "      <td>0.04321</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci37171541</td>\n",
       "      <td>2014-02-01T00:13:20.107Z</td>\n",
       "      <td>10km WNW of Progreso, Mexico</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          latitude  longitude  depth   mag magType  nst  \\\n",
       "time                                                                      \n",
       "2014-01-31 23:53:37.000  60.252000  -152.7081  90.20  1.10      ml  NaN   \n",
       "2014-01-31 23:48:35.452  37.070300  -115.1309   0.00  1.33      ml    4   \n",
       "2014-01-31 23:47:24.000  64.671700  -149.2528   7.10  1.30      ml  NaN   \n",
       "2014-01-31 23:30:54.000  63.188700  -148.9575  96.50  0.80      ml  NaN   \n",
       "2014-01-31 23:30:52.210  32.616833  -115.6925  10.59  1.34      ml    6   \n",
       "\n",
       "                            gap     dmin     rms net          id  \\\n",
       "time                                                               \n",
       "2014-01-31 23:53:37.000     NaN      NaN  0.2900  ak  ak11155107   \n",
       "2014-01-31 23:48:35.452  171.43  0.34200  0.0247  nn  nn00436847   \n",
       "2014-01-31 23:47:24.000     NaN      NaN  1.0000  ak  ak11151142   \n",
       "2014-01-31 23:30:54.000     NaN      NaN  1.0700  ak  ak11151135   \n",
       "2014-01-31 23:30:52.210  285.00  0.04321  0.2000  ci  ci37171541   \n",
       "\n",
       "                                          updated  \\\n",
       "time                                                \n",
       "2014-01-31 23:53:37.000  2014-02-05T19:34:41.515Z   \n",
       "2014-01-31 23:48:35.452  2014-02-01T01:35:09.000Z   \n",
       "2014-01-31 23:47:24.000  2014-02-01T00:03:53.010Z   \n",
       "2014-01-31 23:30:54.000  2014-01-31T23:41:25.007Z   \n",
       "2014-01-31 23:30:52.210  2014-02-01T00:13:20.107Z   \n",
       "\n",
       "                                                     place        type  \n",
       "time                                                                    \n",
       "2014-01-31 23:53:37.000  26km S of Redoubt Volcano, Alaska  earthquake  \n",
       "2014-01-31 23:48:35.452            32km S of Alamo, Nevada  earthquake  \n",
       "2014-01-31 23:47:24.000   12km NNW of North Nenana, Alaska  earthquake  \n",
       "2014-01-31 23:30:54.000         22km S of Cantwell, Alaska  earthquake  \n",
       "2014-01-31 23:30:52.210       10km WNW of Progreso, Mexico  earthquake  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #great for reading .csv and .txt files\n",
    "\n",
    "uri1 = 'http://www.ldeo.columbia.edu/~rpa/usgs_earthquakes_2014.csv' #example from Ryan's worskshop\n",
    "\n",
    "d1 = pd.read_csv(uri1,index_col='time') #many argument options (see pandas website for all the details)\n",
    "\n",
    "type(d1)\n",
    "\n",
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date  B    C\n",
      "A                  \n",
      "1  20151001  a  2.5\n",
      "2  20151002  b  5.0\n",
      "3  20151003  c  7.5\n"
     ]
    }
   ],
   "source": [
    "uri2 = 'http://karensmith.squarespace.com/storage/python_test.csv'\n",
    "\n",
    "d2 = pd.read_csv(uri2) #default case (no arguments)\n",
    "\n",
    "d2.head()\n",
    "\n",
    "\n",
    "d2 = pd.read_csv(uri2,index_col=1) #can pass arguments to specify column order\n",
    "\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20151001</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20151002</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20151003</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  A  B    C\n",
       "0  20151001  1  a  2.5\n",
       "1  20151002  2  b  5.0\n",
       "2  20151003  3  c  7.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri3 = 'http://karensmith.squarespace.com/storage/python_test.xls'\n",
    "\n",
    "d3 = pd.read_excel(uri3) #pandas can also be used to read .xls files\n",
    "\n",
    "d3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date  B    C\n",
      "A                  \n",
      "1  20151001  a  2.5\n",
      "2  20151002  b  5.0\n",
      "3  20151003  c  7.5\n"
     ]
    }
   ],
   "source": [
    "d1.to_csv('earthquakes_test.csv') #writing our d1 DataFrame object to a .csv file\n",
    "\n",
    "d2.to_excel('new_python_test.xls', sheet_name='Sheet1') #writing our d2 DataFrame object to a .xls file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_64BIT data model, file format UNDEFINED):\n",
       "    Conventions: IRIDL\n",
       "    dimensions(sizes): T(1941), X(180), Y(89), zlev(1)\n",
       "    variables(dimensions): float32 \u001b[4mzlev\u001b[0m(zlev), float32 \u001b[4mX\u001b[0m(X), float32 \u001b[4mY\u001b[0m(Y), float32 \u001b[4mT\u001b[0m(T), int16 \u001b[4msst\u001b[0m(T,zlev,Y,X)\n",
       "    groups: "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "uri = 'http://iridl.ldeo.columbia.edu/SOURCES/.NOAA/.NCDC/.ERSST/.version4/anom/.sst/T/(days%20since%201960-01-01)/streamgridunitconvert/dods'\n",
    "\n",
    "#use 'Dataset' to read file as netcdf4\n",
    "nc = Dataset(uri)\n",
    "\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SST = nc.variables['sst'][:,0] #this is the same as ['sst'[:,0,:,:]] -> gets rid of a degenerate dimension (same as squeeze in matlab)\n",
    "Lat = nc.variables['Y'][:]\n",
    "Lon = nc.variables['X'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a new netcdf file\n",
    "new_nc = Dataset('python_test.nc', 'w', format='NETCDF3_CLASSIC') #w is for writing\n",
    "new_nc.description = 'Example data'\n",
    "\n",
    "# define dimensions\n",
    "new_nc.createDimension('time', None) #record dimension\n",
    "new_nc.createDimension('lat', 72)\n",
    "new_nc.createDimension('lon', 144)\n",
    "\n",
    "# define variables\n",
    "times = new_nc.createVariable('time', 'f8', ('time',))\n",
    "latitudes = new_nc.createVariable('latitude', 'f4', ('lat',))\n",
    "longitudes = new_nc.createVariable('longitude', 'f4', ('lon',))\n",
    "tmp = new_nc.createVariable('tmp', 'f4', ('time', 'lat', 'lon',))\n",
    "\n",
    "# allocate data\n",
    "lats =  np.arange(-90, 90, 2.5) #like Matlab's linspace\n",
    "lons =  np.arange(-180, 180, 2.5)\n",
    "latitudes[:] = lats\n",
    "longitudes[:] = lons\n",
    "for i in range(5):\n",
    "    tmp[i,:,:] = np.random.uniform(size=(len(lats), len(lons))) #default uniform distribution between 0 and 1\n",
    "\n",
    "new_nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) netcdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Example data'\n",
      "(72,)\n",
      "[-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\n",
      " -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\n",
      " -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\n",
      "   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\n",
      "  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\n",
      "  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import netcdf #scipy.io can only read/write netcdf3\n",
    "\n",
    "#read the file we just created above using netcdf4\n",
    "f = netcdf.netcdf_file('python_test.nc', 'r')\n",
    "f\n",
    "\n",
    "\n",
    "print(f.description)\n",
    "lat = f.variables['latitude']\n",
    "print(lat.shape)\n",
    "print(lat[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()\n",
    "#data has to be copied to main memory if we want to process data after we close the netcdf file (see message below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Using numpy to import regular columns of data from .CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "signal = numpy.loadtxt(file_location_and_name, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G) KML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastkml import  kml\n",
    "doc = file(\"Allpoints.kml\").read()\n",
    "k = kml.KML()\n",
    "k.from_string(doc)\n",
    "len(k.features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "geo = gdal.Open\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H) VTK files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'vtk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bc076d074f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mvtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_support\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvtk_to_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load a vtk file as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvtkXMLUnstructuredGridReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'vtk'"
     ]
    }
   ],
   "source": [
    "import vtk\n",
    "from vtk.util.numpy_support import vtk_to_numpy\n",
    "\n",
    "# load a vtk file as input\n",
    "reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "reader.SetFileName(\"my_input_data.vtk\")\n",
    "reader.Update()\n",
    "\n",
    "#Grab a scalar from the vtk file\n",
    "my_vtk_array = reader.GetOutput().GetPointData().GetArray(\"my_scalar_name\")\n",
    "\n",
    "#Get the coordinates of the nodes and the scalar values\n",
    "nodes_nummpy_array = vtk_to_numpy(nodes_vtk_array)\n",
    "my_numpy_array = vtk_to_numpy(my_vtk_array )\n",
    "\n",
    "x,y,z = nodes_nummpy_array[:,0] , nodes_nummpy_array[:,1] , nodes_nummpy_array[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
